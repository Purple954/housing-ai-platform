# Housing Retrofit AI Platform


An end-to-end data engineering and machine learning platform that analyses UK EPC (Energy Performance Certificate) data to identify properties with the highest retrofit potential — predicting energy efficiency gains, cost savings, and CO2 reductions using a multimodal AI model.


---

## What It Does

- Ingests 171,000+ domestic EPC records for Salford via a **bronze → silver → gold medallion pipeline** (DuckDB)
- Trains a **multimodal fusion model** combining text property descriptions (sentence-transformers) and structured EPC features (PyTorch MLP) to predict retrofit scores — CLIP image encoder included, ready for property image integration
- Serves predictions via a **FastAPI REST API** with portfolio aggregation endpoints
- Visualises the full dataset through an interactive **Streamlit dashboard** with charts, filters, and a live prediction tool
- Packaged for deployment via **Docker + Docker Compose**

---

## Tech Stack

| Layer | Technology |
|---|---|
| Data storage | DuckDB |
| ETL pipeline | Python (medallion architecture) |
| Text encoder | sentence-transformers — all-MiniLM-L6-v2 |
| Image encoder | CLIP — openai/clip-vit-base-patch32 |
| Fusion model | PyTorch MLP |
| API | FastAPI + Uvicorn |
| Dashboard | Streamlit + Plotly |
| Containerisation | Docker + Docker Compose |

---

## Project Structure

```
housing-ai-platform/
├── src/
│   ├── etl/            # bronze.py, silver.py, gold.py, run_pipeline.py
│   ├── models/         # text_encoder.py, image_encoder.py, fusion.py, train.py
│   ├── api/            # main.py, schemas.py, predictor.py, db.py
│   └── dashboard/      # app.py
├── data/               # not committed — see Data Setup
├── models/             # not committed — generated by training
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
└── check_setup.py
```

---

## Setup

### 1. Clone and create environment

```bash
git clone https://github.com/Purple954/housing-ai-platform.git
cd housing-ai-platform
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # macOS/Linux
pip install -r requirements.txt
```

### 2. Download EPC data

Register (free) at https://epc.opendatacommunities.org/ and download the **Salford domestic EPC dataset** as a ZIP. Extract `certificates.csv` into:

```
data/raw/certificates.csv
```

Verify everything is ready:

```bash
python check_setup.py
```

### 3. Run the ETL pipeline

```bash
python -m src.etl.run_pipeline
```

This loads, cleans, and builds the gold feature table in `data/processed/housing.duckdb`.

### 4. Train the model

```bash
python -m src.models.train
```

Text embeddings are cached after the first run. Trained weights saved to `models/fusion_model.pt`.

### 5. Run the API

```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

Interactive docs at http://localhost:8000/docs

### 6. Run the dashboard

```bash
streamlit run src/dashboard/app.py
```

Dashboard at http://localhost:8501

---

## Run with Docker

```bash
docker compose up --build
```

Mounts `data/` and `models/` as volumes. API on port 8000, dashboard on port 8501.

> Note: complete steps 2–4 before running Docker so the database and model weights exist on disk.

---

## API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| GET | `/health` | Service health check |
| POST | `/predict` | Submit property features, get retrofit score |
| GET | `/properties` | List properties with optional priority filter |
| GET | `/properties/{lmk_key}` | Single property detail |
| GET | `/portfolio` | Aggregated stats by type / age band |
| GET | `/stats/summary` | Headline figures across full dataset |

---

## Key Results

Training on 103,556 Salford properties:

- **Validation RMSE: 2.09** on a 0–100 retrofit score scale
- **29,550 High-priority properties** identified (avg 27.5 point efficiency gain potential)
- **£28.65M/year** total savings potential across the Salford portfolio
- **180,064 tonnes CO2** saving potential if all properties were retrofitted
